# üéì PROYECTO TFG - RESUMEN EJECUTIVO COMPLETO

## üìã Estado General del Proyecto

### Action Points Implementados

| # | Descripci√≥n | Estado | Entrega |
|---|---|---|---|
| **AP1** | Per-model predictions (gr√°ficos separados) | ‚úÖ COMPLETADO | v1.0 |
| **AP2** | Adaptive selector (elige mejor modelo) | ‚úÖ COMPLETADO | v2.0 |
| **AP3** | Weight evolution (sistema de ranking) | ‚úÖ COMPLETADO | v3.0 |

---

## üèõÔ∏è Arquitectura del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     FRONTEND (React + Vite)                  ‚îÇ
‚îÇ  ‚îú‚îÄ Panel de Predicci√≥n (carga CSVs)                         ‚îÇ
‚îÇ  ‚îú‚îÄ Gr√°ficos Individuales (AP1 - una l√≠nea por modelo)      ‚îÇ
‚îÇ  ‚îú‚îÄ Selector Adaptativo (AP2 - tabla de modelos elegidos)   ‚îÇ
‚îÇ  ‚îî‚îÄ Evoluci√≥n de Pesos (AP3 - gr√°fico + tabla de pesos)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ HTTP
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              BACKEND (FastAPI - Orchestrator)                ‚îÇ
‚îÇ  ‚îú‚îÄ /api/series?id=X                                         ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ Devuelve: observed, predicted, models, chosen_models ‚îÇ
‚îÇ  ‚îÇ             + NEW: weights evolution                      ‚îÇ
‚îÇ  ‚îî‚îÄ Queries a InfluxDB para agregar datos                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ InfluxDB Queries
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              INFLUXDB 2.7 (Time Series DB)                   ‚îÇ
‚îÇ  Measurements:                                               ‚îÇ
‚îÇ  ‚îú‚îÄ telemetry (var, prediction)                              ‚îÇ
‚îÇ  ‚îú‚îÄ telemetry_models (per-model yhat + model tag)           ‚îÇ
‚îÇ  ‚îú‚îÄ chosen_model (AP2 - best model per timestamp)            ‚îÇ
‚îÇ  ‚îî‚îÄ weights (AP3 - cumulative weight evolution)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚ñ≤ Write
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          COLLECTOR (Python - window_collector)               ‚îÇ
‚îÇ  Lee mensajes de Kafka y escribe en InfluxDB                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ Kafka: telemetry.agent.out
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              AGENT (Python - Main Processor)                 ‚îÇ
‚îÇ  Core Logic:                                                 ‚îÇ
‚îÇ  ‚îú‚îÄ predict(buffer) ‚Üí {combined_yhat, per_model_yhat}      ‚îÇ
‚îÇ  ‚îú‚îÄ update_weights(y_real):                                  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ AP3: Ranking + Points                                ‚îÇ
‚îÇ  ‚îÇ     1. weights -= 1.0 (penalizaci√≥n)                     ‚îÇ
‚îÇ  ‚îÇ     2. ranked = sort by error                             ‚îÇ
‚îÇ  ‚îÇ     3. assign points: M, M-1, ..., 1                     ‚îÇ
‚îÇ  ‚îî‚îÄ Env√≠a mensaje enriquecido con hyper_weights             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ Kafka: telemetry.agent.in
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            DATA LOADER (window_loader)                       ‚îÇ
‚îÇ  Lee CSVs y produce a Kafka telemetry.agent.in               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîë Componentes Principales

### 1. HyperModel (N√∫cleo de Predicci√≥n)

**Archivo**: `services/agent/hypermodel/hyper_model.py`

**Modelos Disponibles**:
- `linear_8` - Linear regression (window=8)
- `poly2_12` - Polynomial degree 2 (window=12)
- `ab_fast` - Alpha-Beta filter (Œ±=0.9, Œ≤=0.01)

**Modos**:
- `weighted` - Promedio ponderado (no usado actualmente)
- `adaptive` - Selecciona mejor modelo per timestamp (AP2)

**AP3 Implementation**:
```python
def update_weights(self, y_true: float):
    # 1. Penalizar todos
    for name in self.w:
        self.w[name] -= 1.0
    
    # 2. Ranking
    ranked = sorted(errors.items(), key=lambda kv: kv[1])
    
    # 3. Puntos
    for rank, (name, _) in enumerate(ranked):
        reward = len(ranked) - rank
        self.w[name] += reward
```

### 2. Agent (Predictor Principal)

**Archivo**: `services/agent/main.py`

**Flujo**:
1. Lee datos de `telemetry.agent.in` (Kafka)
2. Mantiene buffer circular de √∫ltimas N observaciones
3. Para cada mensaje:
   - Agrega al buffer
   - Predice con HyperModel
   - Actualiza pesos (AP3)
   - Enriquece mensaje con telemetr√≠a
   - Publica a `telemetry.agent.out`

**Mensaje Enriquecido**:
```json
{
  "id": "TestSeries",
  "yhat": 5.234,
  "hyper_y_hat": 5.234,
  "hyper_models": {"linear_8": 5.1, "poly2_12": 5.3, "ab_fast": 5.2},
  "hyper_weights": {"linear_8": 45.2, "poly2_12": -12.5, "ab_fast": 15.8},
  "hyper_chosen": "linear_8",
  "hyper_errors": {"linear_8": 0.1, "poly2_12": 0.5, "ab_fast": 0.2}
}
```

### 3. Collector (Writer a BD)

**Archivo**: `services/window_collector/main.py`

**Escribe a InfluxDB**:
- `telemetry` (var, prediction)
- `telemetry_models` (per-model predictions)
- `chosen_model` (AP2)
- `weights` (AP3) ‚Üê NEW

### 4. Orchestrator (API)

**Archivo**: `services/orchestrator/app.py`

**Endpoint Principal**: `GET /api/series?id=X&hours=24`

**Respuesta**:
```json
{
  "id": "TestSeries",
  "observed": [...],
  "predicted": [...],
  "models": {
    "linear_8": [...],
    "poly2_12": [...],
    "ab_fast": [...]
  },
  "chosen_models": [
    {"t": "2025-11-26T18:30:00Z", "model": "linear_8"},
    ...
  ],
  "weights": {
    "linear_8": [
      {"time": "2025-11-26T18:30:00Z", "weight": 2.0},
      ...
    ],
    ...
  },
  "points": [...]
}
```

### 5. Frontend (UI)

**Archivo**: `frontend/src/components/DataPipelineLiveViewer.jsx`

**Paneles**:

1. **üìä Gr√°fico Combinado** (AP1)
   - L√≠nea observada (negro)
   - L√≠nea predicha (azul)
   - Background con datos

2. **üìà Vista Individual por Modelo** (AP1)
   - Un gr√°fico por modelo
   - Colores diferenciados
   - Comparaci√≥n observado vs predicci√≥n

3. **üéØ Selector Adaptativo** (AP2)
   - Tabla con timestamps
   - Modelo elegido en cada instante
   - √öltimos 20 puntos

4. **‚öñÔ∏è Evoluci√≥n de Pesos** (AP3) ‚Üê NEW
   - Gr√°fico con l√≠nea por modelo
   - Tabla con √∫ltimos pesos
   - Explicaci√≥n del algoritmo

---

## üìä AP3 En Detalle

### ¬øQu√© Es AP3?

Sistema de **ranking acumulativo** que asigna puntos a modelos basado en desempe√±o relativo.

### Algoritmo Paso a Paso

**Cada timestamp (t)**:

```
1. Input: y_real(t), predictions = {linear_8: yh1, poly2_12: yh2, ab_fast: yh3}

2. Calcular errores:
   errors = {
     linear_8: |y_real - yh1|,
     poly2_12: |y_real - yh2|,
     ab_fast: |y_real - yh3|
   }

3. Penalizar a todos:
   for model in models:
     weights[model] -= 1.0

4. Ranking (ordenar por error ascendente):
   ranked = [ab_fast(0.0), linear_8(0.1), poly2_12(0.5)]

5. Asignar puntos:
   ab_fast:   weights[ab_fast] += 3   (mejor)
   linear_8:  weights[linear_8] += 2  (medio)
   poly2_12:  weights[poly2_12] += 1  (peor)

6. Resultado acumulado:
   weights = {
     linear_8: 45.2,    (crece)
     poly2_12: -12.5,   (decrece)
     ab_fast: 15.8      (estable)
   }
```

### Visualizaci√≥n AP3

**Gr√°fico de Evoluci√≥n**:
- Eje X: Tiempo
- Eje Y: Peso acumulado
- Tres l√≠neas (una por modelo)
- Colores: linear_8=#6366F1, poly2_12=#EC4899, ab_fast=#10B981

**Tabla de Pesos**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Modelo   ‚îÇ Peso   ‚îÇ Tendencia ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇlinear_8  ‚îÇ +45.2  ‚îÇ    ‚¨ÜÔ∏è      ‚îÇ
‚îÇab_fast   ‚îÇ +15.8  ‚îÇ    ‚Üí      ‚îÇ
‚îÇpoly2_12  ‚îÇ -12.5  ‚îÇ    ‚¨áÔ∏è      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Interpretaci√≥n

- **Peso ALTO** (>20): Modelo confiable
- **Peso POSITIVO** (>0): Funciona mejor que promedio
- **Peso CERO** (‚âà0): Rendimiento promedio
- **Peso NEGATIVO** (<0): Falla consistentemente
- **Diferencia AMPLIA** (50-(-10)): Clustering claro

---

## üß™ C√≥mo Probar (Gu√≠a R√°pida)

### PASO 1: Preparar Datos
```bash
# Frontend: http://localhost:5173
# ‚Üí Click "üìÇ Cargar CSV"
# ‚Üí Selecciona: data/test_csvs/sine_300.csv
```

### PASO 2: Ejecutar Agente
```bash
# ‚Üí Click "üöÄ Ejecutar agente"
# ‚Üí Espera 15-20 segundos
```

### PASO 3: Verificar Logs
```bash
docker logs docker-agent-1 --tail 30 | grep "\[pred\]"
# Deber√≠as ver: [pred] id=TestSeries y=... y_hat=... chosen=linear_8
```

### PASO 4: Cargar en Frontend
```bash
# ‚Üí En panel "üìä Predicci√≥n"
# ‚Üí Dropdown: TestSeries
# ‚Üí Click "üìä Cargar Series"
```

### PASO 5: Ver Resultados
```bash
# Scroll down, ver√°s:
# ‚úÖ Gr√°fico combinado (AP1)
# ‚úÖ Gr√°ficos individuales (AP1)
# ‚úÖ Tabla selector adaptativo (AP2)
# ‚úÖ Gr√°fico evoluci√≥n pesos (AP3)
# ‚úÖ Tabla √∫ltimos pesos (AP3)
```

---

## üìÅ Archivos Clave del Proyecto

```
TFG_Agente_Data/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ agent/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                    ‚Üê Predictor principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hypermodel/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hyper_model.py         ‚Üê update_weights() con AP3
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ linear_model.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ poly_model.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alphabeta.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_config.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ window_collector/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                    ‚Üê Guarda en InfluxDB
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.py                     ‚Üê API + _query_weights()
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ common/
‚îÇ       ‚îî‚îÄ‚îÄ trace.py
‚îÇ
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DataPipelineLiveViewer.jsx   ‚Üê Panel AP1/AP2/AP3
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CsvChart.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.jsx
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îÇ
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.agent
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.orchestrator
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.window_collector
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile.window_loader
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ test_csvs/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sine_300.csv               ‚Üê Peque√±o (pruebas r√°pidas)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sine_900.csv               ‚Üê Mediano
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sine_1800_doub.csv         ‚Üê Grande (pruebas completas)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ test_ap2.sh                    ‚Üê Verificar AP2
‚îÇ   ‚îî‚îÄ‚îÄ test_ap3.sh                    ‚Üê Verificar AP3
‚îÇ
‚îú‚îÄ‚îÄ AP1_VISUALIZACION_MODELOS.md       ‚Üê Documentaci√≥n AP1
‚îú‚îÄ‚îÄ AP2_SELECTOR_ADAPTATIVO.md         ‚Üê Documentaci√≥n AP2
‚îú‚îÄ‚îÄ AP3_SISTEMA_PESOS.md               ‚Üê Documentaci√≥n AP3
‚îú‚îÄ‚îÄ AP3_GUIA_VERIFICACION.md           ‚Üê Gu√≠a prueba AP3
‚îú‚îÄ‚îÄ AP3_SUMMARY.md                     ‚Üê Resumen AP3
‚îî‚îÄ‚îÄ README.md                          ‚Üê Este archivo
```

---

## üöÄ Pr√≥ximos Pasos Recomendados

### Corto Plazo (Esta semana)
- [ ] Ejecutar pruebas completas de AP1, AP2, AP3
- [ ] Capturar screenshots de cada panel
- [ ] Verificar datos en InfluxDB
- [ ] Documentar resultados

### Mediano Plazo (Pr√≥xima semana)
- [ ] Escribir secci√≥n "Resultados" de tesis con screenshots
- [ ] Decidir si implementar AP4 (opcional)
- [ ] Preparar presentaci√≥n para tutor

### Largo Plazo (Antes del 8 de diciembre)
- [ ] Presentar a tutor
- [ ] Incorporar feedback
- [ ] Versi√≥n final de documentaci√≥n
- [ ] Entrega de tesis

---

## üìö Para Tu Tesis

### Estructura Recomendada

**Secci√≥n: Implementaci√≥n**
```
4.1 Action Point 1: Visualizaci√≥n Per-Modelo (AP1)
    4.1.1 Motivaci√≥n: Necesidad de ver cada modelo
    4.1.2 Implementaci√≥n: Backend + Frontend
    4.1.3 Resultados: Screenshots de gr√°ficos

4.2 Action Point 2: Selector Adaptativo (AP2)
    4.2.1 Motivaci√≥n: Elegir mejor modelo por timestamp
    4.2.2 Implementaci√≥n: Algoritmo de selecci√≥n
    4.2.3 Resultados: Screenshots de tabla adaptativa

4.3 Action Point 3: Sistema de Pesos (AP3)
    4.3.1 Motivaci√≥n: Cuantificar desempe√±o hist√≥rico
    4.3.2 Implementaci√≥n: Ranking acumulativo
    4.3.3 Resultados: Screenshots de evoluci√≥n de pesos
    4.3.4 An√°lisis: Interpretaci√≥n de pesos
```

### P√°rrafos de Ejemplo

**Para AP3**:
> "El Action Point 3 implementa un sistema acumulativo de puntos basado en ranking que proporciona una m√©trica cuantitativa del desempe√±o hist√≥rico de cada modelo. En cada timestamp, los modelos se ordenan seg√∫n su error, asign√°ndose puntos de forma que el mejor recibe M puntos y el peor recibe 1, permitiendo que los pesos negativos emerjan naturalmente como indicador de fallo consistente. Este sistema crea un historial transparente que facilita la evaluaci√≥n de confiabilidad."

---

## üéØ Checklist Final

- [x] AP1: Gr√°ficos separados por modelo
- [x] AP2: Selector adaptativo (tabla de modelos elegidos)
- [x] AP3: Evoluci√≥n de pesos con ranking
- [x] Backend: Orchestrator con /api/series extendido
- [x] InfluxDB: Measurements para chosen_model y weights
- [x] Frontend: Paneles visualizaci√≥n AP1, AP2, AP3
- [x] Docker: Im√°genes reconstruidas y servicios activos
- [x] Documentaci√≥n: 4 archivos MD + esta gu√≠a
- [x] Scripts: test_ap2.sh, test_ap3.sh

---

## üìû Troubleshooting R√°pido

| Problema | Soluci√≥n |
|----------|----------|
| No veo datos en el frontend | Ejecuta: `docker logs docker-agent-1 \| grep "[pred]"` |
| Pesos no cambian | Verifica que hay nuevo CSV proces√°ndose |
| InfluxDB vac√≠o | Espera 30 segundos + refresh browser |
| API devuelve error | Verifica que el ID exacto existe |
| Contenedores no inician | `docker-compose down && docker-compose up -d` |

---

## üìñ Documentaci√≥n

- **AP3_SISTEMA_PESOS.md**: Documentaci√≥n t√©cnica detallada
- **AP3_GUIA_VERIFICACION.md**: Gu√≠a paso-a-paso para pruebas
- **AP3_SUMMARY.md**: Resumen ejecutivo
- **README.md**: Este archivo

---

**Estado**: ‚úÖ LISTO PARA PRUEBAS

**√öltima actualizaci√≥n**: 2025-11-26

**Autor**: Sistema Autom√°tico
