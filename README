# TFG\_Agente\_Data â€” Pipeline de TelemetrÃ­a con Kafka (Semana 1)

> **Estado**: pipeline base funcionando (modo `identity`). Loader â†’ Kafka â†’ Agent â†’ Kafka â†’ Collector â†’ Parquet.

---

## ğŸ§­ Resumen

Este repo contiene un pipeline mÃ­nimo para ingerir un bloque de datos (CSV), moverlo por **Kafka**, procesarlo con un **Agent** (por ahora identidad) y persistir el resultado en **Parquet** mediante un **Collector**.

* **Objetivo**: tener un esqueleto de arquitectura event-driven sobre Kafka y comprobar fin a fin que los datos fluyen y se validan.
* **Resultado esperado**: un fichero `/app/data/processed_window.parquet` con 900 filas (3 unidades Ã— 300 muestras) idÃ©nticas al CSV de entrada en modo `identity`.

---

## ğŸ—ï¸ Arquitectura

```mermaid
flowchart LR
    A[window_loader] -- produce --> T1[(telemetry.raw)]
    T1 -- consume --> AGENT
    AGENT -- produce --> T2[(telemetry.agent.out)]
    T2 -- consume --> C[window_collector]
    C -- write --> F[(processed_window.parquet)]

    subgraph Kafka
      T1
      T2
    end
```

### Servicios

* **kafka**: broker de mensajerÃ­a (Bitnami 3.7, KRaft).
* **orchestrator** (FastAPI): endpoint `/trigger` para resetear el collector e iniciar el loader.
* **window\_loader** (FastAPI): lee `DATA_PATH` (CSV) y publica mensajes.
* **agent**: consume de Kafka, aplica `PROCESS_MODE` (ahora `identity`) y re-publica.
* **window\_collector** (FastAPI): consume del topic procesado y guarda en `OUTPUT_PATH` (Parquet). `/flush` devuelve conteo de filas escritas.

---

## ğŸ§© TÃ³picos Kafka

* `telemetry.raw` â†’ datos crudos publicados por **window\_loader**.
* `telemetry.agent.in` â†’ (opcional/intermedio) entrada del **agent**.
* `telemetry.agent.out` â†’ salida del **agent**.
* `telemetry.processed` â†’ consumido por **window\_collector** para persistir.

> Nota: en este MVP usamos **1 particiÃ³n** por topic para conservar **orden total**.

---

## âš™ï¸ Variables de entorno (en `config/app.env`)

```env
DATA_PATH=/app/data/simple_window.csv
OUTPUT_PATH=/app/data/processed_window.parquet
KAFKA_BROKER=kafka:9092
PROCESS_MODE=identity
```

* `DATA_PATH`: CSV de entrada montado en el contenedor (`../data` â†’ `/app/data`).
* `OUTPUT_PATH`: ruta del Parquet de salida dentro del contenedor.
* `KAFKA_BROKER`: host\:puerto del broker (dentro de la red de Docker).
* `PROCESS_MODE`: `identity` por defecto (no transforma). Ãštil para pruebas A=B.

`docker-compose.yml` usa `env_file: ../config/app.env` y mapea `../data:/app/data` donde corresponda.

---

## ğŸš€ Quick start

### 0) Requisitos

* Docker Desktop (o equivalente) y `docker compose`.
* `make` (opcional, si usas los targets).

### 1) Construir y levantar

```bash
make build
make up
```

### 2) Lanzar el pipeline

```bash
# OpciÃ³n A: vÃ­a orchestrator
curl -s -X POST http://localhost:8080/trigger | jq .

# OpciÃ³n B: directo al loader
curl -s -X POST http://localhost:8081/start | jq .
```

### 3) Verificar salida

```bash
curl -s http://localhost:8082/flush | jq .
# â†’ { "rows": 900, "path": "/app/data/processed_window.parquet" }

# en host
ls -lh data/processed_window.parquet
```

---

## ğŸ”Œ Endpoints

* **Orchestrator** (`:8080`)

  * `GET /health` â†’ `{status: "ok"}`
  * `POST /trigger` â†’ resetea collector e inicia loader; devuelve JSON con respuesta del loader
* **Window Loader** (`:8081`)

  * `POST /start` â†’ envÃ­a N mensajes al topic de entrada
* **Window Collector** (`:8082`)

  * `POST /reset` â†’ limpia estado interno (si aplica)
  * `GET /flush` â†’ fuerza volcado/retorno de mÃ©tricas `{rows, path}`

---

## ğŸ”„ Flujo de datos (paso a paso)

1. **Loader** lee `DATA_PATH` (CSV) â†’ publica cada fila como mensaje en `telemetry.raw`.
2. **Agent** consume de `telemetry.raw` (o `telemetry.agent.in`), aplica `PROCESS_MODE` y publica en `telemetry.agent.out`.
3. **Collector** consume `telemetry.agent.out` (o `telemetry.processed` segÃºn wiring) y va escribiendo a `OUTPUT_PATH` (Parquet).
4. **Flush** confirma filas persistidas.

---

## âœ… ValidaciÃ³n de contenido (CSV vs Parquet)

ComparaciÃ³n determinista dentro de `window_collector`:

```bash
docker compose exec -T window_collector python - <<'PY'
import pandas as pd
csv="/app/data/simple_window.csv"
parq="/app/data/processed_window.parquet"
a=pd.read_csv(csv)
b=pd.read_parquet(parq)
cols=list(a.columns); b=b[cols]
a=a.sort_values(cols).reset_index(drop=True)
b=b.sort_values(cols).reset_index(drop=True)
print("OK:", a.equals(b))
PY
# Debe imprimir: OK: True (en modo identity)
```

Checks Ãºtiles:

```bash
docker compose exec -T window_collector python - <<'PY'
import pandas as pd
p="/app/data/processed_window.parquet"
df=pd.read_parquet(p)
print("shape:", df.shape)   # (900, 7)
print("nulos:\n", df.isna().sum())
print("dup:", df.duplicated().sum())
print("units:", df["unit_id"].value_counts())
print("ts monotÃ³nica por unidad:", df.sort_values(["unit_id","ts"]).groupby("unit_id")["ts"].is_monotonic_increasing.all())
PY
```

---

## ğŸ› ï¸ Operaciones comunes

Logs rÃ¡pidos:

```bash
# servicio concreto
docker compose logs -f --tail=200 window_loader
# todos
make logs
```

Inspeccionar variables dentro de los contenedores:

```bash
docker compose exec -T window_loader env | egrep 'DATA_PATH|OUTPUT_PATH|KAFKA_BROKER|PROCESS_MODE'
```

Listar datos montados:

```bash
docker compose exec -T window_loader ls -lh /app/data
```

---

## ğŸ§¯ Troubleshooting

* **`jq: Invalid numeric literal` al hacer `make trigger`**

  * Causa: `/trigger` no devolvÃ­a JSON. SoluciÃ³n: devolver un `dict`/JSON en FastAPI (ya estÃ¡ implementado) o quitar `| jq .` del Makefile.

* **Variables vacÃ­as en `window_loader`**

  * Causa: mezclar `env_file` y `environment` mal definidos. SoluciÃ³n: deja solo `env_file: ../config/app.env` o mapea explÃ­cito `environment: {VAR: ${VAR}}`.

* **`FileNotFoundError: /app/data/sample_window.parquet`**

  * Causa: `DATA_PATH` apuntaba a un Parquet inexistente o 0B. SoluciÃ³n: usar `simple_window.csv` o regenerar el fichero.

* **`the input device is not a TTY`**

  * Usa `docker compose exec -T ...` cuando ejecutes Python con heredoc.

* **No se persisten filas**

  * Revisa `window_collector` y su topic de entrada. Comprueba `KAFKA_BROKER` y salud de Kafka.

---

## ğŸŒ¿ Estrategia de ramas (Git)

* `main`: estable, sÃ³lo merges desde `dev` al final del proyecto.
* `dev`: integraciÃ³n continua de semanas.
* Ramas semanales desde `dev`: `w01-environment`, `w02-<tema>`, ... â†’ PR a `dev`.

### Pasos tÃ­picos

```bash
git switch main && git pull --ff-only
git switch -c dev && git push -u origin dev

# Semana 1
git switch dev
git switch -c w01-environment
# ... cambios, README_SEMANA_01.md ...
git add README_SEMANA_01.md && git commit -m "Semana 1: entorno y pipeline Kafka (identity)"
git push -u origin w01-environment
# Abrir PR: w01-environment â†’ dev
```

> Protege `main` (y si quieres `dev`) con reglas de branch en GitHub para evitar pushes directos.

---

## ğŸ“Œ Roadmap de aprendizaje Kafka (mini-guÃ­a)

1. **Offsets**: genera 900 mensajes y observa cÃ³mo avanza el grupo `collector-v1` al reiniciar el collector.
2. **Particiones**: crea topic con `--partitions 3`, produce con key `unit_id` y verifica orden por key.
3. **Fallos simulados**:

   * Apaga `agent` mientras `loader` envÃ­a â†’ se acumulan mensajes. Enciende `agent` y verifica catch-up.
   * Apaga `window_collector` y repite; luego `/flush`.
4. **Transformaciones**: cambia `PROCESS_MODE` (p.ej., `v1 = v1 * 1.1`) y comprueba que ya **no** es `OK: True` (demuestra el papel del agent).

---

## ğŸ“‚ Estructura (simplificada)

```
.
â”œâ”€ config/
â”‚  â””â”€ app.env
â”œâ”€ data/
â”‚  â”œâ”€ simple_window.csv
â”‚  â””â”€ processed_window.parquet   # generado
â”œâ”€ docker/
â”‚  â””â”€ docker-compose.yml
â”œâ”€ services/
â”‚  â”œâ”€ orchestrator/
â”‚  â”œâ”€ window_loader/
â”‚  â”œâ”€ agent/
â”‚  â””â”€ window_collector/
â””â”€ Makefile
```

---

## ğŸ“„ Licencia

Define aquÃ­ la licencia del proyecto (MIT/Apache-2.0/etc.) si aplica.
